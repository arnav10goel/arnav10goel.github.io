---
permalink: /
title: "Arnav Goel"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I am Arnav, a final year undergraduate at IIIT Delhi, where I am pursuing a B.Tech in Computer Science and Artificial Intelligence. Currently, I am working as a Research Intern at the [INK-Lab](https://inklab.usc.edu/index.html), under the guidance of [Dr. Xiang Ren](https://www.seanre.com/). In parallel, I serve as a Research Assistant at McGill University and Mila-Quebec AI Institute, supervised by [Dr. Jackie Chi Kit Cheung](https://www.cs.mcgill.ca/~jcheung/). My work here includes a collaboration with the FATE Team at Microsoft Research Montreal. In the past, I have been fortunate to work under [Dr. Sameep Mehta](https://research.ibm.com/people/sameep-mehta) and [Dr. Nishtha Madaan](https://nishthaa.github.io/) from IBM Research India and [Dr. Anubha Gupta](https://www.iiitd.ac.in/anubha) and [Dr. Rajiv Ratn Shah](https://midas.iiitd.ac.in/) at IIIT Delhi. 

Research
------

My research interests span large language models (LLMs), machine learning, and speech processing. I am currently working on enhancing the transparency, trustworthiness and fairness of large-scale foundation models, with a particular focus on understanding various influences driving their memorization and generalization capabilities. Additionally, I have previously worked on: (1) post-processing solutions to adapt LLMs to enterprise settings, ensuring their safety and robustness; (2) novel architectures and improved representation learning to adapt prosody generation and speech recognition systems to long-tail speaker distributions; (3) measuring representation harms like erasure in NLP systems through a novel conceptualization; and (4) improving LLMs and vision-language models (VLMs) on complex question-answering and reasoning tasks. A full list of my publications is available at [this link](https://arnav10goel.github.io/publications/).

Outside of research, I am a big-time history buff and love spending time watching documentaries. I have recently developed a strong penchant for cooking and enjoy experimenting with new recipes in my free time. Swimming has always been my go-to activity for relaxation, and I am always up for an intense game of squash :)

Feel free to reach out if you would like to chat about large language models (LLMs), explainability, data or machine learning in general. I am also always happy to offer advice to high-schoolers or undergrads exploring their way into AI research. Donâ€™t hesitate to drop me an email if you think I can help!


News
------
- **January 2025**: Selected for the Google Deepmind Research Symposium 2025. Looking forward to connect with people in Bangalore!
- **December 2024**: Paper titled "Optimizing Multimodal Large Language Models for Scientific VQA through Caption-Aware Supervised Training" accepted at the AI4EDU-Workshop @ AAAI-2025! This work was done as part of my research at the MIDAS-Lab @ IIIT-Delhi.
- **October 2024**: My team _DBkaScam_ was placed **6th** amongst 20000+ teams in the prestigious **Amazon ML Challenge 2024**! Check out our winning solution at [this link](https://www.canva.com/design/DAGRau30tRI/06v7kPdBwb99GDjsiv1fcg/edit?utm_content=DAGRau30tRI&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)
- **June 2024**: Full paper titled "Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging Co-Attention Cues in Multitask Learning" accepted at INTERSPEECH 2024. This work was co-led by me as part of my undergraduate thesis at IIIT-Delhi. 
- **May 2024**: Thrilled to share that I have started my internship at the INK-Lab in the USC NLP Group as one of the **15 IUSSTF-Viterbi Research Scholars** selected from all over India. Looking forward to an incredible summer in Los Angeles :)
- **February 2024**: 2 papers on speech processing and multilingual prosody transfer accepted at the Tiny Track at ICLR 2024!
- **November 2023**: Paper titled "LLMGuard: Guarding Against Unsafe LLM Behavior" accepted at the Demonstrations Track at AAAI 2024. This work was done as part of my GRM internship at IBM Research India.
- **August 2023**: 2 papers on improving LLMs in scientific-question answering through RAG and alignment were accepted at BDA-2023. This work was done as part of my research for the Summer Undergraduate Research Fellowship (SURF) at IIIT-Delhi.


